{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbf532",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "import os\n",
    "\n",
    "# First, make sure layoutparser is properly installed with Detectron2\n",
    "# pip install \"layoutparser[detectron2]\"\n",
    "# If you're in Google Colab, you might need:\n",
    "# !pip install \"layoutparser[layoutmodels,detectron2]\"\n",
    "\n",
    "import layoutparser as lp\n",
    "\n",
    "# Initialize PaddleOCR\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang=\"en\", det_db_box_thresh=0.5)\n",
    "\n",
    "# Load Image\n",
    "image_path = \"hdfc.png\"  # Replace with your vendor statement\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# OCR Processing\n",
    "ocr_results = ocr.ocr(image_path, cls=True)\n",
    "\n",
    "# Extracted Text & Bounding Boxes\n",
    "extracted_text = []\n",
    "for result in ocr_results[0]:\n",
    "    try:\n",
    "        if len(result) >= 2:\n",
    "            box = result[0]\n",
    "            text = result[1][0]  \n",
    "            score = result[1][1] \n",
    "            extracted_text.append((text, score))\n",
    "    except (IndexError, TypeError) as e:\n",
    "        print(f\"Skipping result with unexpected format: {result}, Error: {e}\")\n",
    "\n",
    "# Print Extracted Text\n",
    "print(\"ðŸ”¹ Extracted Text from Invoice:\")\n",
    "for text, score in extracted_text:\n",
    "    print(f\"{text} (Confidence: {score:.2f})\")\n",
    "\n",
    "# For layout detection, properly import the Detectron2 model\n",
    "try:\n",
    "    # Import the specific Detectron2LayoutModel\n",
    "    from layoutparser.models import Detectron2LayoutModel\n",
    "\n",
    "    # Initialize the layout model\n",
    "    model = Detectron2LayoutModel(\n",
    "        \"lp://PubLayNet/faster_rcnn_R_50_FPN/mask_rcnn_X_101_32x8d_FPN_3x\",\n",
    "        extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
    "        label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n",
    "    )\n",
    "\n",
    "    # Perform layout detection\n",
    "    layout = model.detect(image)\n",
    "\n",
    "    # Extract table regions\n",
    "    table_blocks = [b for b in layout if b.type == 'Table']\n",
    "    if table_blocks:\n",
    "        print(\"\\nðŸ”¹ Table Detected!\")\n",
    "\n",
    "        for idx, table in enumerate(table_blocks):\n",
    "            x1, y1, x2, y2 = map(int, table.coordinates)\n",
    "            cropped_table = image[y1:y2, x1:x2]\n",
    "\n",
    "            # Run OCR on the cropped table\n",
    "            table_results = ocr.ocr(cropped_table, cls=True)\n",
    "\n",
    "            # Convert to structured format\n",
    "            table_data = []\n",
    "            for result in table_results[0]:\n",
    "                try:\n",
    "                    text = result[1][0]  # Fix the indexing based on PaddleOCR structure\n",
    "                    table_data.append(text)\n",
    "                except (IndexError, TypeError):\n",
    "                    pass\n",
    "\n",
    "            # Attempt to create a structured table\n",
    "            # This is a simplified approach - for production, you'd need more logic\n",
    "            # to determine rows and columns\n",
    "            rows = []\n",
    "            current_row = []\n",
    "\n",
    "            # Very simple approach: group by y-coordinate proximity\n",
    "            if table_results[0]:\n",
    "                sorted_results = sorted(table_results[0], key=lambda x: (x[0][0][1] + x[0][2][1])/2)  # Sort by y-coordinate\n",
    "\n",
    "                current_y = (sorted_results[0][0][0][1] + sorted_results[0][0][2][1])/2\n",
    "\n",
    "                for result in sorted_results:\n",
    "                    y = (result[0][0][1] + result[0][2][1])/2\n",
    "                    text = result[1][0]\n",
    "\n",
    "                    # If y is significantly different, start a new row\n",
    "                    if abs(y - current_y) > 20:  # Threshold of 20 pixels\n",
    "                        if current_row:\n",
    "                            rows.append(current_row)\n",
    "                            current_row = []\n",
    "                        current_y = y\n",
    "\n",
    "                    current_row.append(text)\n",
    "\n",
    "                # Add the last row\n",
    "                if current_row:\n",
    "                    rows.append(current_row)\n",
    "\n",
    "            # Create DataFrame\n",
    "            max_cols = max([len(row) for row in rows]) if rows else 0\n",
    "            df = pd.DataFrame(rows)\n",
    "\n",
    "            print(f\"\\nðŸ”¹ Extracted Table {idx + 1}:\")\n",
    "            print(df)\n",
    "\n",
    "            # Save table to CSV\n",
    "            df.to_csv(f\"invoice_table_{idx + 1}.csv\", index=False)\n",
    "    else:\n",
    "        print(\"\\nðŸ”¹ No tables detected in the image.\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"\\nðŸ”¹ Layout detection error: {e}\")\n",
    "    print(\"Make sure you have the full LayoutParser installation with Detectron2:\")\n",
    "    print(\"pip install 'layoutparser[detectron2]'\")\n",
    "\n",
    "    # Fallback: Create a simple dataframe from all OCR text\n",
    "    all_text = [text for text, _ in extracted_text]\n",
    "    print(\"\\nðŸ”¹ Fallback: Creating a simple data structure from all OCR text\")\n",
    "    df = pd.DataFrame({'text': all_text})\n",
    "    print(df.head())\n",
    "    df.to_csv(\"invoice_extracted_text.csv\", index=False)\n",
    "\n",
    "# Display Image with OCR Text Overlay\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "\n",
    "# Add text annotations\n",
    "for result in ocr_results[0]:\n",
    "    if len(result) >= 2:\n",
    "        box = result[0]\n",
    "        text = result[1][0]\n",
    "\n",
    "        # Convert box coordinates to integers\n",
    "        box = np.array(box).astype(np.int32)\n",
    "\n",
    "        # Draw bounding box\n",
    "        plt.plot([box[0][0], box[1][0], box[2][0], box[3][0], box[0][0]],\n",
    "                [box[0][1], box[1][1], box[2][1], box[3][1], box[0][1]], 'r-')\n",
    "\n",
    "        # Add text annotation\n",
    "        plt.text(box[0][0], box[0][1], text, color='blue', fontsize=8)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"invoice_annotated.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”¹ Processing complete! Annotated image and extracted data saved.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
